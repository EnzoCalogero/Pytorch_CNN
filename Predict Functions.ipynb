{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import PIL \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        ###\n",
    "        model = get_model(architecture=checkpoint['artitecture'], hidden=checkpoint['hidden'])\n",
    "        #model = get_model(architecture='vgg13', hidden = 100)\n",
    "        ####\n",
    "        # epochs = checkpoint['epochs']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model.class_to_idx = checkpoint['image_datasets']\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        model.class_to_idx = {model.class_to_idx[k]: k for k in model.class_to_idx}\n",
    "        \n",
    "        #model.artitecture='vgg13'\n",
    "        #model.hidden=100\n",
    "        #model = get_model(artitecture=model.artitecture, hidden=model.hedden)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    img_loader = transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(224), \n",
    "        transforms.ToTensor()])\n",
    "    \n",
    "    pil_image = Image.open(image)\n",
    "    pil_image = img_loader(pil_image).float()\n",
    "    \n",
    "    np_image = np.array(pil_image)    \n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np.transpose(np_image, (1, 2, 0)) - mean)/std    \n",
    "    np_image = np.transpose(np_image, (2, 0, 1))\n",
    "            \n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(architecture, hidden):\n",
    "    from collections import OrderedDict\n",
    "    #hidden=[1024, 128, 102]\n",
    "    if architecture == 'vgg13':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        classifier_input_size = model.classifier[0].in_features\n",
    "    elif architecture == 'densenet121':\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        classifier_input_size = 1024 \n",
    "    else:\n",
    "        print(\"error\")\n",
    "        stop()\n",
    "    hidden = hidden   \n",
    "    classifier_output_size = 102\n",
    "    # Classificator\n",
    "    \n",
    "    #model = models.vgg16(pretrained=True)\n",
    "    #classifier_input_size = model.classifier[0].in_features\n",
    "\n",
    "    classifier = nn.Sequential(OrderedDict([           \n",
    "                              ('fc1', nn.Linear(classifier_input_size, hidden)), \n",
    "                              ('relu1', nn.ReLU()),\n",
    "                              ('drop',nn.Dropout(p=0.2)),\n",
    "                              ('fc2', nn.Linear(hidden,classifier_output_size)),\n",
    "                              ('output', nn.LogSoftmax(dim=1))\n",
    "                              ]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "\n",
    "    model.cuda()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model,topk=5):\n",
    "\n",
    "    gpu_check = torch.cuda.is_available()\n",
    "    model.eval()\n",
    "    np_array =process_image(image_path)\n",
    "    tensor = torch.from_numpy(np_array)\n",
    "    var_inputs = Variable(tensor.float().cuda(), volatile=True)\n",
    "    output = model.forward(var_inputs.unsqueeze(0))\n",
    "    #probs, classes\n",
    "    ps= torch.exp(output).data.topk(topk)\n",
    "    probs = ps[0].cpu() if gpu_check else ps[0]\n",
    "    classes = ps[1].cpu() if gpu_check else ps[1]\n",
    "   \n",
    "    classes_ = list()\n",
    "    for item in classes.numpy()[0]:\n",
    "        classes_.append(model.class_to_idx[item])\n",
    "    #return probs, classes\n",
    "    return probs.numpy()[0], classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NOOOOOOOOOOO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba125f665112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNOOOOOOOOOOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/54/image_05413.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model=get_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NOOOOOOOOOOO' is not defined"
     ]
    }
   ],
   "source": [
    "NOOOOOOOOOOO\n",
    "image_path = test_dir + '/54/image_05413.jpg'\n",
    "#model=get_model()\n",
    "#model.cuda()\n",
    "model = load_checkpoint('test.pth')\n",
    "#model.class_to_idx = {model.class_to_idx[k]: k for k in model.class_to_idx}\n",
    "probs, classes = predict(image_path, model)\n",
    "\n",
    "print(probs)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainfunction(checkpoint, image_path, map_file='cat_to_name.json', topk=5):\n",
    "        print(\"Start\")\n",
    "        model = load_checkpoint(filepath=checkpoint)\n",
    "        print(\"phase1\")\n",
    "        probs, classes = predict(image_path, model,topk=topk)\n",
    "        print(\"phase2\")\n",
    "        \n",
    "        with open(map_file, 'r') as f:\n",
    "            cat_to_name = json.load(f)\n",
    "        print(\"Flower Name: Associated Probability: \")\n",
    "        for i in range(0, len(classes)):\n",
    "            print(\"{} {:.3f}\".format(cat_to_name[classes[i]], probs[i]))\n",
    "        \n",
    "        return probs, classes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase1\n",
      "phase2\n",
      "Flower Name: Associated Probability: \n",
      "passion flower 0.085\n",
      "pink-yellow dahlia 0.069\n",
      "barbeton daisy 0.062\n",
      "common dandelion 0.055\n",
      "colt's foot 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "probs, classes = mainfunction(checkpoint='test.pth', image_path = test_dir + '/54/image_05413.jpg', topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
